{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train a model"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "``graph-pes-train`` provides a unified interface to train any :class:`~graph_pes.core.GraphPESModel`, including those packaged within :doc:`graph_pes.models <../models/root>` and those defined by you, the user.\n",
                "\n",
                ".. seealso::\n",
                "\n",
                "    For more information on the ``graph-pes-train`` command, and the plethora of options available for specification in your ``config.yaml`` see the :ref:`CLI reference <cli-reference>`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully installed graph-pes-0.0.1\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "pip install graph-pes | tail -n 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now should have access to the ``graph-pes-train`` command. We can check this by running:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "usage: graph-pes-train [-h] [args ...]\n",
                        "\n",
                        "Train a GraphPES model using PyTorch Lightning.\n",
                        "\n",
                        "positional arguments:\n",
                        "  args        Config files and command line specifications. Config files\n",
                        "              should be YAML (.yaml/.yml) files. Command line specifications\n",
                        "              should be in the form nested^key=value. Final config is built up\n",
                        "              from these items in a left to right manner, with later items\n",
                        "              taking precedence over earlier ones in the case of conflicts.\n",
                        "\n",
                        "options:\n",
                        "  -h, --help  show this help message and exit\n",
                        "\n",
                        "Copyright 2023-24, John Gardner\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "graph-pes-train -h"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ase.io\n",
                "from load_atoms import load_dataset\n",
                "\n",
                "structures = load_dataset(\"QM7\")\n",
                "train, test = structures.random_split([0.8, 0.2])\n",
                "\n",
                "ase.io.write(\"train.xyz\", train)\n",
                "ase.io.write(\"test.xyz\", test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "Great - now lets train a model. To do this, we have specified the following in our ``quickstart-config.yaml`` file:\n",
                "\n",
                "* the model architecture to instantiate and train (here :class:`~graph_pes.models.PaiNN`) \n",
                "* the data to train on (here the `QM7 <https://jla-gardner.github.io/load-atoms/datasets/QM7.html>`_ dataset downloaded internally using `load-atoms <https://jla-gardner.github.io/load-atoms/>`_) \n",
                "* the loss function to use (here a simple :class:`~graph_pes.training.loss.PerAtomEnergyLoss`) \n",
                "* and various other training hyperparameters (e.g. the learning rate, batch size, etc.)\n",
                "\n",
                ".. literalinclude:: quickstart-config.yaml\n",
                "    :language: yaml\n",
                "    :caption: quickstart-config.yaml\n",
                "    :linenos:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Let's train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Set logging level to INFO\n",
                        "[graph-pes INFO]: Started training at 2024-10-14 14:38:52.397\n",
                        "[graph-pes INFO]: Output directory: graph-pes-results/quickstart-run\n",
                        "[graph-pes INFO]: \n",
                        "Logging using WandbLogger(\n",
                        "  project=\"graph-pes-demo\",\n",
                        "  id=\"quickstart-run\",\n",
                        "  save_dir=\"graph-pes-results\"\n",
                        ")\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "wandb: Currently logged in as: jla-gardner. Use `wandb login --relogin` to force relogin\n",
                        "wandb: wandb version 0.18.3 is available!  To upgrade, please run:\n",
                        "wandb:  $ pip install wandb --upgrade\n",
                        "wandb: Tracking run with wandb version 0.17.1\n",
                        "wandb: Run data is saved locally in graph-pes-results/wandb/run-20241014_143853-quickstart-run\n",
                        "wandb: Run `wandb offline` to turn off syncing.\n",
                        "wandb: Resuming run quickstart-run\n",
                        "wandb: ‚≠êÔ∏è View project at https://wandb.ai/jla-gardner/graph-pes-demo\n",
                        "wandb: üöÄ View run at https://wandb.ai/jla-gardner/graph-pes-demo/runs/quickstart-run\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Logging to graph-pes-results/quickstart-run/logs/rank-0.log\n",
                        "[graph-pes INFO]: \n",
                        "model:\n",
                        "   graph_pes.models.PaiNN:\n",
                        "      layers: 3\n",
                        "      cutoff: 3.0\n",
                        "data:\n",
                        "   graph_pes.data.load_atoms_dataset:\n",
                        "      id: QM7\n",
                        "      cutoff: 3.0\n",
                        "      n_train: 1000\n",
                        "      n_valid: 100\n",
                        "loss: graph_pes.training.loss.PerAtomEnergyLoss()\n",
                        "fitting:\n",
                        "   pre_fit_model: true\n",
                        "   max_n_pre_fit: 5000\n",
                        "   early_stopping_patience: null\n",
                        "   trainer_kwargs:\n",
                        "      max_epochs: 200\n",
                        "      accelerator: auto\n",
                        "      enable_model_summary: false\n",
                        "   loader_kwargs:\n",
                        "      num_workers: 0\n",
                        "      persistent_workers: false\n",
                        "      batch_size: 16\n",
                        "      pin_memory: false\n",
                        "   optimizer:\n",
                        "      graph_pes.training.opt.Optimizer:\n",
                        "         name: AdamW\n",
                        "         lr: 0.0001\n",
                        "   scheduler: null\n",
                        "   swa: null\n",
                        "general:\n",
                        "   seed: 42\n",
                        "   root_dir: graph-pes-results\n",
                        "   run_id: quickstart-run\n",
                        "   log_level: INFO\n",
                        "   progress: logged\n",
                        "wandb:\n",
                        "   project: graph-pes-demo\n",
                        "\n",
                        "[graph-pes INFO]: \n",
                        "FittingData(\n",
                        "  train=ASEDataset(1,000, labels=['energy']),\n",
                        "  valid=ASEDataset(100, labels=['energy'])\n",
                        ")\n",
                        "\n",
                        "[graph-pes INFO]: Optimizer(name=\"AdamW\", lr=0.0001)\n",
                        "[graph-pes INFO]: No LR scheduler.\n",
                        "[graph-pes INFO]: \n",
                        "TotalLoss:\n",
                        "    (weight) : (loss)\n",
                        "         1.0 : PerAtomEnergyLoss(\"energy\", metric=MAE())\n",
                        "\n",
                        "[graph-pes INFO]: Starting training on rank 0.\n",
                        "[graph-pes INFO]: Preparing data\n",
                        "[graph-pes INFO]: Setting up datasets\n",
                        "[graph-pes INFO]: Pre-fitting the model on 1,000 samples\n",
                        "[graph-pes INFO]: \n",
                        "Model:\n",
                        "PaiNN(\n",
                        "  (z_embedding): PerElementEmbedding(\n",
                        "    dim=32,\n",
                        "    elements=['H', 'C', 'N', 'O', 'S']\n",
                        "  )\n",
                        "  (interactions): UniformModuleList(\n",
                        "    (0-2): 3 x Interaction(\n",
                        "      (filter_generator): HaddamardProduct(\n",
                        "        (components): ModuleList(\n",
                        "          (0): Sequential(\n",
                        "            (0): Bessel(n_features=20, cutoff=3.0, trainable=True)\n",
                        "            (1): Linear(in_features=20, out_features=96, bias=True)\n",
                        "          )\n",
                        "          (1): PolynomialEnvelope(cutoff=3.0, p=6)\n",
                        "        )\n",
                        "      )\n",
                        "      (Phi): MLP(32 ‚Üí 32 ‚Üí 96, activation=SiLU())\n",
                        "    )\n",
                        "  )\n",
                        "  (updates): UniformModuleList(\n",
                        "    (0-2): 3 x Update(\n",
                        "      (U): VectorLinear(\n",
                        "        (_linear): Linear(in_features=32, out_features=32, bias=False)\n",
                        "      )\n",
                        "      (V): VectorLinear(\n",
                        "        (_linear): Linear(in_features=32, out_features=32, bias=False)\n",
                        "      )\n",
                        "      (mlp): MLP(64 ‚Üí 32 ‚Üí 96, activation=SiLU())\n",
                        "    )\n",
                        "  )\n",
                        "  (read_out): MLP(32 ‚Üí 32 ‚Üí 1, activation=SiLU())\n",
                        ")\n",
                        "\n",
                        "[graph-pes INFO]: Number of learnable params : 41,922\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "/u/vld/jesu2890/miniconda3/envs/graphs/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
                        "/u/vld/jesu2890/miniconda3/envs/graphs/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   epoch   valid/loss/total   valid/loss/per_atom_energy_mae_component   timer/its_per_s/train   timer/its_per_s/valid\n",
                        "       0            4.07476                                    4.07476                83.33334               207.14285\n",
                        "       1            2.65200                                    2.65200                83.33334               202.38097\n",
                        "       2            0.39732                                    0.39732                90.90909               221.42857\n",
                        "       3            0.28913                                    0.28913                90.90909               214.28572\n",
                        "       4            0.21064                                    0.21064                83.33334               207.14285\n",
                        "       5            0.16655                                    0.16655                90.90909               209.52380\n",
                        "       6            0.14174                                    0.14174                83.33334               207.14285\n",
                        "       7            0.11001                                    0.11001                90.90909               207.14285\n",
                        "       8            0.07531                                    0.07531                83.33334               195.23811\n",
                        "       9            0.07800                                    0.07800                90.90909               221.42857\n",
                        "      10            0.06353                                    0.06353                90.90909               207.14285\n",
                        "      11            0.05848                                    0.05848                83.33334               207.14285\n",
                        "      12            0.04867                                    0.04867                90.90909               207.14285\n",
                        "      13            0.05278                                    0.05278                83.33334               221.42857\n",
                        "      14            0.04153                                    0.04153                83.33334               202.38097\n",
                        "      15            0.05332                                    0.05332                90.90909               207.14285\n",
                        "      16            0.03670                                    0.03670                83.33334               207.14285\n",
                        "      17            0.03446                                    0.03446                90.90909               214.28572\n",
                        "      18            0.03590                                    0.03590                90.90909               228.57143\n",
                        "      19            0.04893                                    0.04893                90.90909               214.28572\n",
                        "      20            0.02976                                    0.02976                90.90909               207.14285\n",
                        "      21            0.02954                                    0.02954                90.90909               207.14285\n",
                        "      22            0.02848                                    0.02848                90.90909               207.14285\n",
                        "      23            0.02673                                    0.02673                83.33334               198.97960\n",
                        "      24            0.02796                                    0.02796               100.00000               200.00000\n",
                        "      25            0.04376                                    0.04376                90.90909               221.42857\n",
                        "      26            0.02499                                    0.02499                83.33334               207.14285\n",
                        "      27            0.02478                                    0.02478                90.90909               200.00000\n",
                        "      28            0.02468                                    0.02468                83.33334               207.14285\n",
                        "      29            0.02364                                    0.02364                90.90909               207.14285\n",
                        "      30            0.02464                                    0.02464                90.90909               221.42857\n",
                        "      31            0.02550                                    0.02550                90.90909               214.28572\n",
                        "      32            0.02531                                    0.02531                83.33334               214.28572\n",
                        "      33            0.02372                                    0.02372                83.33334               195.23811\n",
                        "      34            0.02286                                    0.02286                90.90909               214.28572\n",
                        "      35            0.02638                                    0.02638                83.33334               214.28572\n",
                        "      36            0.02250                                    0.02250                83.33334               200.00000\n",
                        "      37            0.03974                                    0.03974                83.33334               221.42857\n",
                        "      38            0.02692                                    0.02692                83.33334               221.42857\n",
                        "      39            0.02354                                    0.02354                83.33334               221.42857\n",
                        "      40            0.02151                                    0.02151                90.90909               214.28572\n",
                        "      41            0.02506                                    0.02506                90.90909               207.14285\n",
                        "      42            0.02139                                    0.02139                90.90909               228.57143\n",
                        "      43            0.01954                                    0.01954                90.90909               221.42857\n",
                        "      44            0.01905                                    0.01905                90.90909               214.28572\n",
                        "      45            0.02579                                    0.02579                90.90909               228.57143\n",
                        "      46            0.03646                                    0.03646                90.90909               228.57143\n",
                        "      47            0.01866                                    0.01866                90.90909               214.28572\n",
                        "      48            0.01865                                    0.01865                90.90909               221.42857\n",
                        "      49            0.01778                                    0.01778                90.90909               207.14285\n",
                        "      50            0.01804                                    0.01804                90.90909               214.28572\n",
                        "      51            0.01788                                    0.01788                90.90909               228.57143\n",
                        "      52            0.01737                                    0.01737                90.90909               221.42857\n",
                        "      53            0.01881                                    0.01881                90.90909               221.42857\n",
                        "      54            0.01945                                    0.01945                90.90909               221.42857\n",
                        "      55            0.01970                                    0.01970                90.90909               214.28572\n",
                        "      56            0.01625                                    0.01625                90.90909               221.42857\n",
                        "      57            0.01739                                    0.01739                90.90909               221.42857\n",
                        "      58            0.01697                                    0.01697                90.90909               228.57143\n",
                        "      59            0.01904                                    0.01904                90.90909               221.42857\n",
                        "      60            0.01706                                    0.01706                90.90909               214.28572\n",
                        "      61            0.03017                                    0.03017                90.90909               221.42857\n",
                        "      62            0.01579                                    0.01579                90.90909               228.57143\n",
                        "      63            0.01675                                    0.01675                71.42857               221.42857\n",
                        "      64            0.02363                                    0.02363                90.90909               221.42857\n",
                        "      65            0.02283                                    0.02283                90.90909               207.14285\n",
                        "      66            0.01595                                    0.01595                90.90909               221.42857\n",
                        "      67            0.01589                                    0.01589               100.00000               221.42857\n",
                        "      68            0.01651                                    0.01651                90.90909               221.42857\n",
                        "      69            0.01831                                    0.01831                90.90909               221.42857\n",
                        "      70            0.01771                                    0.01771                90.90909               214.28572\n",
                        "      71            0.02240                                    0.02240                90.90909               228.57143\n",
                        "      72            0.02890                                    0.02890                83.33334               221.42857\n",
                        "      73            0.01589                                    0.01589                90.90909               228.57143\n",
                        "      74            0.02092                                    0.02092                90.90909               228.57143\n",
                        "      75            0.01743                                    0.01743                90.90909               221.42857\n",
                        "      76            0.02188                                    0.02188                83.33334               200.00000\n",
                        "      77            0.02064                                    0.02064                90.90909               221.42857\n",
                        "      78            0.01774                                    0.01774                83.33334               214.28572\n",
                        "      79            0.02288                                    0.02288                90.90909               214.28572\n",
                        "      80            0.01538                                    0.01538                90.90909               200.00000\n",
                        "      81            0.01505                                    0.01505                90.90909               214.28572\n",
                        "      82            0.02053                                    0.02053                90.90909               214.28572\n",
                        "      83            0.01436                                    0.01436                90.90909               207.14285\n",
                        "      84            0.01645                                    0.01645                90.90909               207.14285\n",
                        "      85            0.01518                                    0.01518                90.90909               207.14285\n",
                        "      86            0.01640                                    0.01640                90.90909               221.42857\n",
                        "      87            0.03329                                    0.03329                90.90909               207.14285\n",
                        "      88            0.01887                                    0.01887                90.90909               214.28572\n",
                        "      89            0.01899                                    0.01899                83.33334               207.14285\n",
                        "      90            0.01411                                    0.01411                83.33334               221.42857\n",
                        "      91            0.01393                                    0.01393                90.90909               221.42857\n",
                        "      92            0.01375                                    0.01375                71.42857               200.00000\n",
                        "      93            0.01522                                    0.01522                83.33334               207.14285\n",
                        "      94            0.01469                                    0.01469                90.90909               228.57143\n",
                        "      95            0.02108                                    0.02108                90.90909               221.42857\n",
                        "      96            0.01371                                    0.01371                90.90909               207.14285\n",
                        "      97            0.01381                                    0.01381                90.90909               221.42857\n",
                        "      98            0.01393                                    0.01393                90.90909               228.57143\n",
                        "      99            0.01383                                    0.01383                90.90909               214.28572\n",
                        "     100            0.01341                                    0.01341                90.90909               214.28572\n",
                        "     101            0.01392                                    0.01392                83.33334               207.14285\n",
                        "     102            0.01372                                    0.01372                90.90909               207.14285\n",
                        "     103            0.01328                                    0.01328                90.90909               214.28572\n",
                        "     104            0.01278                                    0.01278                90.90909               207.14285\n",
                        "     105            0.01446                                    0.01446                90.90909               221.42857\n",
                        "     106            0.01306                                    0.01306                90.90909               221.42857\n",
                        "     107            0.01388                                    0.01388                83.33334               228.57143\n",
                        "     108            0.01496                                    0.01496                83.33334               214.28572\n",
                        "     109            0.02202                                    0.02202                90.90909               214.28572\n",
                        "     110            0.01401                                    0.01401                90.90909               200.00000\n",
                        "     111            0.01388                                    0.01388                90.90909               214.28572\n",
                        "     112            0.01362                                    0.01362                90.90909               214.28572\n",
                        "     113            0.01428                                    0.01428                83.33334               207.14285\n",
                        "     114            0.01456                                    0.01456                90.90909               221.42857\n",
                        "     115            0.01259                                    0.01259                90.90909               214.28572\n",
                        "     116            0.02072                                    0.02072                90.90909               214.28572\n",
                        "     117            0.01349                                    0.01349                83.33334               207.14285\n",
                        "     118            0.02340                                    0.02340                83.33334               207.14285\n",
                        "     119            0.01379                                    0.01379                90.90909               221.42857\n",
                        "     120            0.01703                                    0.01703                90.90909               214.28572\n",
                        "     121            0.01690                                    0.01690                90.90909               228.57143\n",
                        "     122            0.01281                                    0.01281                90.90909               214.28572\n",
                        "     123            0.01404                                    0.01404                90.90909               200.00000\n",
                        "     124            0.02069                                    0.02069                83.33334               221.42857\n",
                        "     125            0.01520                                    0.01520                90.90909               221.42857\n",
                        "     126            0.02517                                    0.02517                90.90909               221.42857\n",
                        "     127            0.01260                                    0.01260                90.90909               200.00000\n",
                        "     128            0.01639                                    0.01639               100.00000               200.00000\n",
                        "     129            0.01295                                    0.01295                90.90909               221.42857\n",
                        "     130            0.01361                                    0.01361                90.90909               214.28572\n",
                        "     131            0.01288                                    0.01288                90.90909               221.42857\n",
                        "     132            0.01299                                    0.01299                90.90909               207.14285\n",
                        "     133            0.01267                                    0.01267                90.90909               228.57143\n",
                        "     134            0.01320                                    0.01320                90.90909               221.42857\n",
                        "     135            0.01889                                    0.01889                90.90909               228.57143\n",
                        "     136            0.01501                                    0.01501                90.90909               207.14285\n",
                        "     137            0.01243                                    0.01243                90.90909               207.14285\n",
                        "     138            0.01460                                    0.01460                90.90909               200.00000\n",
                        "     139            0.01154                                    0.01154                90.90909               214.28572\n",
                        "     140            0.01250                                    0.01250                83.33334               228.57143\n",
                        "     141            0.01330                                    0.01330                90.90909               214.28572\n",
                        "     142            0.01283                                    0.01283                83.33334               207.14285\n",
                        "     143            0.01361                                    0.01361                83.33334               221.42857\n",
                        "     144            0.01192                                    0.01192                90.90909               214.28572\n",
                        "     145            0.01439                                    0.01439                90.90909               228.57143\n",
                        "     146            0.01459                                    0.01459                71.42857               207.14285\n",
                        "     147            0.01324                                    0.01324                90.90909               207.14285\n",
                        "     148            0.01267                                    0.01267                83.33334               200.00000\n",
                        "     149            0.01347                                    0.01347                90.90909               214.28572\n",
                        "     150            0.01189                                    0.01189               100.00000               221.42857\n",
                        "     151            0.01446                                    0.01446                90.90909               198.97960\n",
                        "     152            0.01296                                    0.01296                83.33334               221.42857\n",
                        "     153            0.01273                                    0.01273                90.90909               207.14285\n",
                        "     154            0.01256                                    0.01256                90.90909               214.28572\n",
                        "     155            0.01639                                    0.01639                90.90909               214.28572\n",
                        "     156            0.01218                                    0.01218                90.90909               221.42857\n",
                        "     157            0.01529                                    0.01529                90.90909               214.28572\n",
                        "     158            0.01468                                    0.01468                90.90909               214.28572\n",
                        "     159            0.01590                                    0.01590                83.33334               207.14285\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "export LOAD_ATOMS_VERBOSE=0  # disable load-atoms progress bars\n",
                "graph-pes-train quickstart-config.yaml"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "trash",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
