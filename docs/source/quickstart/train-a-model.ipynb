{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train a model"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "``graph-pes-train`` provides a unified interface to train any :class:`~graph_pes.core.GraphPESModel`, including those packaged within :doc:`graph_pes.models <../models/root>` and those defined by you, the user.\n",
                "\n",
                ".. seealso::\n",
                "\n",
                "    For more information on the ``graph-pes-train`` command, and the plethora of options available for specification in your ``config.yaml`` see the :ref:`CLI reference <cli-reference>`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully installed graph-pes-0.0.1\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "pip install graph-pes | tail -n 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now should have access to the ``graph-pes-train`` command. We can check this by running:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "usage: graph-pes-train [-h] [args ...]\n",
                        "\n",
                        "Train a GraphPES model using PyTorch Lightning.\n",
                        "\n",
                        "positional arguments:\n",
                        "  args        Config files and command line specifications. Config files\n",
                        "              should be YAML (.yaml/.yml) files. Command line specifications\n",
                        "              should be in the form nested^key=value. Final config is built up\n",
                        "              from these items in a left to right manner, with later items\n",
                        "              taking precedence over earlier ones in the case of conflicts.\n",
                        "\n",
                        "options:\n",
                        "  -h, --help  show this help message and exit\n",
                        "\n",
                        "Copyright 2023-24, John Gardner\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "graph-pes-train -h"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data definition\n",
                "\n",
                "We use [load-atoms](https://jla-gardner.github.io/load-atoms/) to download and split the QM7 dataset into training, validation and test datasets:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9a2f04716fb047b9b559302ff7a2ad1c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Output()"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                        ],
                        "text/plain": []
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import ase.io\n",
                "from load_atoms import load_dataset\n",
                "\n",
                "structures = load_dataset(\"QM7\")\n",
                "train, val, test = structures.random_split([0.8, 0.1, 0.1])\n",
                "\n",
                "ase.io.write(\"train.xyz\", train)\n",
                "ase.io.write(\"val.xyz\", val)\n",
                "ase.io.write(\"test.xyz\", test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "Great - now lets train a model. To do this, we have specified the following in our ``quickstart-config.yaml`` file:\n",
                "\n",
                "* the model architecture to instantiate and train (here :class:`~graph_pes.models.PaiNN`) \n",
                "* the data to train on (here the `QM7 <https://jla-gardner.github.io/load-atoms/datasets/QM7.html>`_ dataset downloaded internally using `load-atoms <https://jla-gardner.github.io/load-atoms/>`_) \n",
                "* the loss function to use (here a simple :class:`~graph_pes.training.loss.PerAtomEnergyLoss`) \n",
                "* and various other training hyperparameters (e.g. the learning rate, batch size, etc.)\n",
                "\n",
                ".. literalinclude:: quickstart-config.yaml\n",
                "    :language: yaml\n",
                "    :caption: quickstart-config.yaml\n",
                "    :linenos:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Let's train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Seed set to 42\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Set logging level to INFO\n",
                        "[graph-pes INFO]: Started training at 2024-10-14 15:03:08.163\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "wandb: Currently logged in as: jla-gardner. Use `wandb login --relogin` to force relogin\n",
                        "wandb: wandb version 0.18.3 is available!  To upgrade, please run:\n",
                        "wandb:  $ pip install wandb --upgrade\n",
                        "wandb: Tracking run with wandb version 0.17.1\n",
                        "wandb: Run data is saved locally in graph-pes-results/wandb/run-20241014_150309-quickstart-run-2\n",
                        "wandb: Run `wandb offline` to turn off syncing.\n",
                        "wandb: Resuming run quickstart-run-2\n",
                        "wandb: ‚≠êÔ∏è View project at https://wandb.ai/jla-gardner/graph-pes-demo\n",
                        "wandb: üöÄ View run at https://wandb.ai/jla-gardner/graph-pes-demo/runs/quickstart-run-2\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Logging to graph-pes-results/quickstart-run-2/logs/rank-0.log\n",
                        "[graph-pes INFO]: Starting training on rank 0.\n",
                        "[graph-pes INFO]: Preparing data\n",
                        "[graph-pes INFO]: Caching neighbour lists for 1000 structures with cutoff 3.0\n",
                        "[graph-pes INFO]: Caching neighbour lists for 716 structures with cutoff 3.0\n",
                        "[graph-pes INFO]: Setting up datasets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/miniconda3/envs/graph-pes/lib/python3.8/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
                        "  return torch.load(io.BytesIO(b))\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[graph-pes INFO]: Pre-fitting the model on 1,000 samples\n",
                        "[graph-pes INFO]: \n",
                        "Model:\n",
                        "PaiNN(\n",
                        "  (z_embedding): PerElementEmbedding(\n",
                        "    dim=32,\n",
                        "    elements=['H', 'C', 'N', 'O', 'S']\n",
                        "  )\n",
                        "  (interactions): UniformModuleList(\n",
                        "    (0-2): 3 x Interaction(\n",
                        "      (filter_generator): HaddamardProduct(\n",
                        "        (components): ModuleList(\n",
                        "          (0): Sequential(\n",
                        "            (0): Bessel(n_features=20, cutoff=3.0, trainable=True)\n",
                        "            (1): Linear(in_features=20, out_features=96, bias=True)\n",
                        "          )\n",
                        "          (1): PolynomialEnvelope(cutoff=3.0, p=6)\n",
                        "        )\n",
                        "      )\n",
                        "      (Phi): MLP(32 ‚Üí 32 ‚Üí 96, activation=SiLU())\n",
                        "    )\n",
                        "  )\n",
                        "  (updates): UniformModuleList(\n",
                        "    (0-2): 3 x Update(\n",
                        "      (U): VectorLinear(\n",
                        "        (_linear): Linear(in_features=32, out_features=32, bias=False)\n",
                        "      )\n",
                        "      (V): VectorLinear(\n",
                        "        (_linear): Linear(in_features=32, out_features=32, bias=False)\n",
                        "      )\n",
                        "      (mlp): MLP(64 ‚Üí 32 ‚Üí 96, activation=SiLU())\n",
                        "    )\n",
                        "  )\n",
                        "  (read_out): MLP(32 ‚Üí 32 ‚Üí 1, activation=SiLU())\n",
                        ")\n",
                        "\n",
                        "[graph-pes INFO]: Number of learnable params : 41,922\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/miniconda3/envs/graph-pes/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
                        "/opt/miniconda3/envs/graph-pes/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   epoch   valid/loss/total   valid/loss/per_atom_energy_mae_component   timer/its_per_s/train   timer/its_per_s/valid\n",
                        "       0            4.08356                                    4.08356                 0.94697                 5.03226\n",
                        "Error while terminating subprocess (pid=40564): \n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "bash: line 3: 40566 Killed: 9               graph-pes-train quickstart-config.yaml\n"
                    ]
                }
            ],
            "source": [
                "%%bash\n",
                "\n",
                "export LOAD_ATOMS_VERBOSE=0  # disable load-atoms progress bars\n",
                "graph-pes-train quickstart-config.yaml"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "trash",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
